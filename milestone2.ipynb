{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from numpy import matlib\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "from mpl_toolkits.mplot3d import Axes3D\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import cross_validate, KFold, train_test_split, cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, silhouette_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.ensemble import GradientBoostingRegressor,RandomForestRegressor\n",
    "from sklearn.neural_network import MLPRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing functions\n",
    "def deleteMissingValues(dataFrame):\n",
    "    dataTr = np.array(dataFrame)\n",
    "    \n",
    "    # characterize missing values\n",
    "    ifDataMiss = np.sum(np.isnan(dataTr))\n",
    "    # delete missing values\n",
    "    if ifDataMiss != 0:\n",
    "        indNaN = np.argwhere(dataTr == np.NaN)\n",
    "        rowDelete = indNaN[:,0]\n",
    "        data = np.delete(dataTr, rowDelete, axis=0)\n",
    "        dataTr = data\n",
    "    \n",
    "    return dataTr\n",
    "\n",
    "def errorCorrection(data):\n",
    "    N,dim = np.shape(data)\n",
    "\n",
    "    dataFeatures = data[:,0:-1]\n",
    "    dataFtMean = np.mean(dataFeatures, axis=0)\n",
    "    dataFtStd  = np.std(dataFeatures, axis=0)\n",
    "\n",
    "    dataFtCmp = matlib.repmat(4 * dataFtStd, N, 1)\n",
    "\n",
    "    indError = np.argwhere(np.abs(dataFeatures - dataFtMean) > dataFtCmp)\n",
    "    rowError = indError[:,0]\n",
    "    rowDelete = np.unique(rowError)\n",
    "\n",
    "    dataCoE = np.delete(data, rowDelete, axis=0)\n",
    "\n",
    "    return dataCoE\n",
    "\n",
    "def rescaleData(data):\n",
    "    N,dim = np.shape(data)\n",
    "\n",
    "    dataTarget = np.reshape(data[:,-1],[N,1])\n",
    "    dataFeatures = data[:,0:-1]\n",
    "\n",
    "    scaler = MinMaxScaler()\n",
    "    scaler.fit(dataFeatures)\n",
    "    dataNormdFeatures = scaler.transform(dataFeatures)\n",
    "\n",
    "    dataNormd = np.append(dataNormdFeatures,dataTarget,axis=1)\n",
    "\n",
    "    return dataNormd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data preprocessing\n",
    "dfTr = pd.read_csv('train.csv')\n",
    "# get the names of the column header\n",
    "featureNames = list(dfTr.columns)\n",
    "\n",
    "dataTr = deleteMissingValues(dfTr)\n",
    "\n",
    "dataTrCoE = errorCorrection(dataTr)\n",
    "dfCoE= pd.DataFrame(dataTrCoE, columns=featureNames)\n",
    "dfCoE.to_csv('train_CoE.csv', index=False, header=True) \n",
    "\n",
    "dataTrNormd = rescaleData(dataTr)\n",
    "dfNormd= pd.DataFrame(dataTrNormd, columns=featureNames)\n",
    "dfNormd.to_csv('train_Normd.csv', index=False, header=True) \n",
    "\n",
    "dataTrCoENormd = rescaleData(dataTrCoE)\n",
    "dfCoENormd = pd.DataFrame(dataTrCoENormd, columns=featureNames)\n",
    "dfCoENormd.to_csv('train_CoE_Normd.csv', index=False, header=True) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random forest error calculation\n",
    "def RFRegressorErrorCalc(X, Y, splitNum):\n",
    "    inSampleError = []\n",
    "    outSampleError = []\n",
    "    kf = KFold(n_splits = splitNum)\n",
    "    for train, test in kf.split(X, Y):\n",
    "        RFRegr = RandomForestRegressor() # Used squared loss, which is default\n",
    "        RFRegr.fit(X.iloc[train,:], Y.iloc[train])\n",
    "        inSampleError = np.append(inSampleError,(RFRegr.predict(X.iloc[train,:])-Y.iloc[train])**2)\n",
    "        outSampleError = np.append(outSampleError,(RFRegr.predict(X.iloc[test,:])-Y.iloc[test])**2)\n",
    "\n",
    "    return inSampleError, outSampleError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfRaw = pd.read_csv('train.csv')\n",
    "dfNormd = pd.read_csv('train_Normd.csv')\n",
    "\n",
    "\n",
    "# random forest regression, raw data & normalized data\n",
    "XRaw = dfRaw.drop(columns='target')\n",
    "YRaw = dfRaw['target']\n",
    "XNormd = dfNormd.drop(columns='target')\n",
    "YNormd = dfNormd['target']\n",
    "cvNum = 5\n",
    "\n",
    "# errors\n",
    "rawDataRFInSampleError, rawDataRFOutSampleError = RFRegressorErrorCalc(XRaw, YRaw, cvNum)\n",
    "normdDataRFInSampleError, normdDataRFOutSampleError = RFRegressorErrorCalc(XNormd, YNormd, cvNum)\n",
    "\n",
    "# paired t-test\n",
    "errorCmpRes = [\n",
    "stats.ttest_rel(rawDataRFInSampleError, normdDataRFInSampleError),\n",
    "stats.ttest_rel(rawDataRFOutSampleError, normdDataRFOutSampleError),\n",
    "]\n",
    "print(\"Raw Data & Normalized Data In-sample Error T-Test: \\n\", \"T-statistic =\", round(tuple(errorCmpRes[0])[0], 4), \", pvalue =\", round(tuple(errorCmpRes[0])[1], 4), \"\\n\")\n",
    "print(\"Raw Data & Normalized Data Out-of-sample Error T-Test: \\n\", \"T-statistic =\", round(tuple(errorCmpRes[1])[0], 4), \", pvalue =\", round(tuple(errorCmpRes[1])[1], 4), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means clustering\n",
    "\n",
    "df = pd.read_csv('train_normd.csv')\n",
    "X = np.array(df.drop('target', axis=1))\n",
    "target = np.array(df['target']).reshape(-1,1)\n",
    "N, dim = np.shape(X)\n",
    "\n",
    "kList = np.append(np.array([2]), np.arange(5,501,5))\n",
    "silhouetteAvgScoreList = np.array([])\n",
    "inertiaList = np.array([])\n",
    "rmseTrList = np.array([])\n",
    "rmseTeList = np.array([])\n",
    "for indk in range(len(kList)):\n",
    "    k = kList[indk]\n",
    "    kmeansModel = KMeans(n_clusters=k, random_state=0, n_init=\"auto\")\n",
    "    KMCl = kmeansModel.fit(X)\n",
    "    clCenters = KMCl.cluster_centers_\n",
    "    clLabels = KMCl.labels_\n",
    "\n",
    "    silhouetteAvgScore = silhouette_score(X, clLabels)\n",
    "    silhouetteAvgScoreList = np.append(silhouetteAvgScoreList,silhouetteAvgScore)\n",
    "    inertiaList = np.append(inertiaList, kmeansModel.inertia_)\n",
    "\n",
    "    distDataCtr = np.zeros(shape=[N, k])\n",
    "    for i in range(k):\n",
    "        centerCalc = clCenters[i, :]\n",
    "        dist = np.linalg.norm((X - centerCalc), axis=1)\n",
    "        distDataCtr[:, i] = dist\n",
    "\n",
    "    if k == 2:\n",
    "        max_dist = np.max([1.05*np.max(distDataCtr[:, 0]), 1.1*np.max(distDataCtr[:, 1])])\n",
    "        fig1 = plt.figure()\n",
    "        plt.scatter(distDataCtr[:, 0], distDataCtr[:, 1], c=target, cmap='plasma', s=10)\n",
    "        plt.colorbar()\n",
    "        plt.plot([0, max_dist], [0, max_dist])\n",
    "        plt.xlabel('Distance from Cluster Center 1')\n",
    "        plt.ylabel('Distance from Cluster Center 2')\n",
    "        plt.title('K-Means Clustering')\n",
    "        plt.xlim((0, max_dist))\n",
    "        plt.ylim((0, max_dist))\n",
    "        fig1.show()\n",
    "\n",
    "    XTr, XTe, yTr, yTe = train_test_split(distDataCtr, target, test_size=0.2)\n",
    "    \n",
    "    lrModel = LinearRegression()\n",
    "    lrModel.fit(XTr, yTr)\n",
    "\n",
    "    yPredTr = lrModel.predict(XTr)\n",
    "    yPred = lrModel.predict(XTe)\n",
    "\n",
    "    rmseTr = mean_squared_error(yTr, yPredTr, squared=False)\n",
    "    rmseTe = mean_squared_error(yTe, yPred, squared=False)\n",
    "    if k == 2:\n",
    "        print(\"Training RMSE = \", rmseTr)\n",
    "        print(\"Training RMSE = \", rmseTe)\n",
    "\n",
    "    rmseTrList = np.append(rmseTrList, rmseTr)\n",
    "    rmseTeList = np.append(rmseTeList, rmseTe)\n",
    "\n",
    "figRMSE = plt.figure()\n",
    "plt.plot(kList, rmseTrList, label=\"Training RMSE\")\n",
    "plt.plot(kList, rmseTeList, label=\"Testing RMSE\")\n",
    "figRMSE.legend()\n",
    "plt.xlabel('number of clusters')\n",
    "plt.ylabel('RMSE')\n",
    "figRMSE.show()\n",
    "\n",
    "figScore = plt.figure()\n",
    "plt.plot(kList, silhouetteAvgScoreList)\n",
    "plt.xlabel('number of clusters')\n",
    "plt.ylabel('silhouette score')\n",
    "figScore.show()\n",
    "\n",
    "figInertia = plt.figure()\n",
    "plt.plot(kList, inertiaList)\n",
    "plt.xlabel('number of clusters')\n",
    "plt.ylabel('inertia')\n",
    "figInertia.show()"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
